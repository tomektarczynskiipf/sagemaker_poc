{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "700317bf-bfe5-4a1a-8dd6-9a24bd819908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mlflow==2.13.2 in /opt/conda/lib/python3.10/site-packages (2.13.2)\n",
      "Requirement already satisfied: sagemaker-mlflow==0.1.0 in /opt/conda/lib/python3.10/site-packages (0.1.0)\n",
      "Requirement already satisfied: cloudpickle==2.2.1 in /opt/conda/lib/python3.10/site-packages (2.2.1)\n",
      "Requirement already satisfied: Flask<4 in /opt/conda/lib/python3.10/site-packages (from mlflow==2.13.2) (3.0.3)\n",
      "Requirement already satisfied: alembic!=1.10.0,<2 in /opt/conda/lib/python3.10/site-packages (from mlflow==2.13.2) (1.13.2)\n",
      "Requirement already satisfied: cachetools<6,>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from mlflow==2.13.2) (5.3.3)\n",
      "Requirement already satisfied: click<9,>=7.0 in /opt/conda/lib/python3.10/site-packages (from mlflow==2.13.2) (8.1.7)\n",
      "Requirement already satisfied: docker<8,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from mlflow==2.13.2) (7.1.0)\n",
      "Requirement already satisfied: entrypoints<1 in /opt/conda/lib/python3.10/site-packages (from mlflow==2.13.2) (0.4)\n",
      "Requirement already satisfied: gitpython<4,>=3.1.9 in /opt/conda/lib/python3.10/site-packages (from mlflow==2.13.2) (3.1.43)\n",
      "Requirement already satisfied: graphene<4 in /opt/conda/lib/python3.10/site-packages (from mlflow==2.13.2) (3.3)\n",
      "Requirement already satisfied: importlib-metadata!=4.7.0,<8,>=3.7.0 in /opt/conda/lib/python3.10/site-packages (from mlflow==2.13.2) (6.10.0)\n",
      "Requirement already satisfied: markdown<4,>=3.3 in /opt/conda/lib/python3.10/site-packages (from mlflow==2.13.2) (3.6)\n",
      "Requirement already satisfied: matplotlib<4 in /opt/conda/lib/python3.10/site-packages (from mlflow==2.13.2) (3.8.4)\n",
      "Requirement already satisfied: numpy<2 in /opt/conda/lib/python3.10/site-packages (from mlflow==2.13.2) (1.26.4)\n",
      "Requirement already satisfied: opentelemetry-api<3,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from mlflow==2.13.2) (1.25.0)\n",
      "Requirement already satisfied: opentelemetry-sdk<3,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from mlflow==2.13.2) (1.25.0)\n",
      "Requirement already satisfied: packaging<25 in /opt/conda/lib/python3.10/site-packages (from mlflow==2.13.2) (23.2)\n",
      "Requirement already satisfied: pandas<3 in /opt/conda/lib/python3.10/site-packages (from mlflow==2.13.2) (2.1.4)\n",
      "Requirement already satisfied: protobuf<5,>=3.12.0 in /opt/conda/lib/python3.10/site-packages (from mlflow==2.13.2) (4.24.4)\n",
      "Requirement already satisfied: pyarrow<16,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from mlflow==2.13.2) (15.0.0)\n",
      "Requirement already satisfied: pytz<2025 in /opt/conda/lib/python3.10/site-packages (from mlflow==2.13.2) (2023.3)\n",
      "Requirement already satisfied: pyyaml<7,>=5.1 in /opt/conda/lib/python3.10/site-packages (from mlflow==2.13.2) (6.0.1)\n",
      "Requirement already satisfied: querystring-parser<2 in /opt/conda/lib/python3.10/site-packages (from mlflow==2.13.2) (1.2.4)\n",
      "Requirement already satisfied: requests<3,>=2.17.3 in /opt/conda/lib/python3.10/site-packages (from mlflow==2.13.2) (2.32.3)\n",
      "Requirement already satisfied: scikit-learn<2 in /opt/conda/lib/python3.10/site-packages (from mlflow==2.13.2) (1.4.2)\n",
      "Requirement already satisfied: scipy<2 in /opt/conda/lib/python3.10/site-packages (from mlflow==2.13.2) (1.11.4)\n",
      "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from mlflow==2.13.2) (2.0.30)\n",
      "Requirement already satisfied: sqlparse<1,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from mlflow==2.13.2) (0.5.0)\n",
      "Requirement already satisfied: Jinja2<4,>=2.11 in /opt/conda/lib/python3.10/site-packages (from mlflow==2.13.2) (3.1.4)\n",
      "Requirement already satisfied: gunicorn<23 in /opt/conda/lib/python3.10/site-packages (from mlflow==2.13.2) (22.0.0)\n",
      "Requirement already satisfied: boto3>=1.34 in /opt/conda/lib/python3.10/site-packages (from sagemaker-mlflow==0.1.0) (1.34.131)\n",
      "Requirement already satisfied: Mako in /opt/conda/lib/python3.10/site-packages (from alembic!=1.10.0,<2->mlflow==2.13.2) (1.3.5)\n",
      "Requirement already satisfied: typing-extensions>=4 in /opt/conda/lib/python3.10/site-packages (from alembic!=1.10.0,<2->mlflow==2.13.2) (4.12.2)\n",
      "Requirement already satisfied: botocore<1.35.0,>=1.34.131 in /opt/conda/lib/python3.10/site-packages (from boto3>=1.34->sagemaker-mlflow==0.1.0) (1.34.131)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from boto3>=1.34->sagemaker-mlflow==0.1.0) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /opt/conda/lib/python3.10/site-packages (from boto3>=1.34->sagemaker-mlflow==0.1.0) (0.10.2)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /opt/conda/lib/python3.10/site-packages (from docker<8,>=4.0.0->mlflow==2.13.2) (1.26.19)\n",
      "Requirement already satisfied: Werkzeug>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from Flask<4->mlflow==2.13.2) (3.0.3)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in /opt/conda/lib/python3.10/site-packages (from Flask<4->mlflow==2.13.2) (2.2.0)\n",
      "Requirement already satisfied: blinker>=1.6.2 in /opt/conda/lib/python3.10/site-packages (from Flask<4->mlflow==2.13.2) (1.8.2)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from gitpython<4,>=3.1.9->mlflow==2.13.2) (4.0.11)\n",
      "Requirement already satisfied: graphql-core<3.3,>=3.1 in /opt/conda/lib/python3.10/site-packages (from graphene<4->mlflow==2.13.2) (3.2.3)\n",
      "Requirement already satisfied: graphql-relay<3.3,>=3.1 in /opt/conda/lib/python3.10/site-packages (from graphene<4->mlflow==2.13.2) (3.2.0)\n",
      "Requirement already satisfied: aniso8601<10,>=8 in /opt/conda/lib/python3.10/site-packages (from graphene<4->mlflow==2.13.2) (9.0.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata!=4.7.0,<8,>=3.7.0->mlflow==2.13.2) (3.19.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from Jinja2<4,>=2.11->mlflow==2.13.2) (2.1.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib<4->mlflow==2.13.2) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib<4->mlflow==2.13.2) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib<4->mlflow==2.13.2) (4.53.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib<4->mlflow==2.13.2) (1.4.5)\n",
      "Requirement already satisfied: pillow>=8 in /opt/conda/lib/python3.10/site-packages (from matplotlib<4->mlflow==2.13.2) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib<4->mlflow==2.13.2) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib<4->mlflow==2.13.2) (2.9.0)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-api<3,>=1.0.0->mlflow==2.13.2) (1.2.14)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.46b0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-sdk<3,>=1.0.0->mlflow==2.13.2) (0.46b0)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas<3->mlflow==2.13.2) (2024.1)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from querystring-parser<2->mlflow==2.13.2) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.17.3->mlflow==2.13.2) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.17.3->mlflow==2.13.2) (3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.17.3->mlflow==2.13.2) (2024.6.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn<2->mlflow==2.13.2) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn<2->mlflow==2.13.2) (3.5.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from sqlalchemy<3,>=1.4.0->mlflow==2.13.2) (3.0.3)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /opt/conda/lib/python3.10/site-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.0.0->mlflow==2.13.2) (1.14.1)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow==2.13.2) (5.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install mlflow==2.13.2 sagemaker-mlflow==0.1.0 cloudpickle==2.2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "887d7724-a8bf-4acb-9e41-31103fc4e9f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "import sagemaker.session\n",
    "import os\n",
    "from sagemaker.workflow.pipeline_context import PipelineSession\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.workflow.steps import ProcessingStep\n",
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "from sagemaker.workflow.steps import TrainingStep\n",
    "from sagemaker.sklearn.model import SKLearnModel\n",
    "from sagemaker.workflow.model_step import ModelStep\n",
    "from sagemaker.transformer import Transformer\n",
    "from sagemaker.workflow.steps import TransformStep\n",
    "from sagemaker.inputs import TransformInput\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "from scripts.functions import *\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "settings = read_settings('scripts/settings.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cad5b983-ecfa-4a47-bcbc-2fe9a1ccf9c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delete: s3://sagemaker-bucket-ds/01-churn/v1/data/inference_train/inference_train.csv\n",
      "delete: s3://sagemaker-bucket-ds/01-churn/v1/data/test/test.csv\n",
      "delete: s3://sagemaker-bucket-ds/01-churn/v1/data/train/train.csv\n",
      "delete: s3://sagemaker-bucket-ds/01-churn/v1/output/inference_train/inference_train.csv.out\n",
      "delete: s3://sagemaker-bucket-ds/01-churn/v1/data/valid/valid.csv\n"
     ]
    }
   ],
   "source": [
    "!aws s3 rm s3://sagemaker-bucket-ds/01-churn/v1-prod --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5f07cdf-a77c-4c1a-8a58-e73df6c4b04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "region = boto3.Session().region_name\n",
    "sagemaker_session = sagemaker.session.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "default_bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "pipeline_session = PipelineSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce529c68-e253-43ee-bb57-99851b0f2d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting scripts/processing.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile scripts/processing.py\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def create_random_dataframe_with_params(n_rows, n_cols, params, seed=None):\n",
    "    \"\"\"\n",
    "    Create a DataFrame with random values and an additional binary target column based on the sum of products of values and parameters.\n",
    "    \n",
    "    Parameters:\n",
    "    - n_rows: int, number of rows in the DataFrame\n",
    "    - n_cols: int, number of columns in the DataFrame\n",
    "    - params: list or array-like, parameters for each column\n",
    "    - seed: int, random seed for reproducibility (default is None)\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame with shape (n_rows, n_cols+1) where the last column is a binary target based on the sum of products.\n",
    "    \"\"\"\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "        \n",
    "    if len(params) != n_cols:\n",
    "        raise ValueError(\"The length of params must be equal to the number of columns (n_cols).\")\n",
    "    \n",
    "    data = np.random.rand(n_rows, n_cols)\n",
    "    df = pd.DataFrame(data, columns=[f'col_{i+1}' for i in range(n_cols)])\n",
    "    \n",
    "    # Calculate the sum_product column\n",
    "    df['sum_product'] = np.dot(df.values, params) + 0.5\n",
    "    \n",
    "    # Calculate the target column\n",
    "    df['target'] = (np.random.rand(n_rows) < df['sum_product']).astype(int)\n",
    "    \n",
    "    # Drop the sum_product column\n",
    "    df = df.drop(columns=['sum_product'])\n",
    "\n",
    "    # Move target column to the first position\n",
    "    columns = ['target'] + [col for col in df.columns if col != 'target']\n",
    "    df = df[columns]    \n",
    "    \n",
    "    return df\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    settings = os.environ\n",
    "    \n",
    "    # Create data\n",
    "    params = [-1, -1, -0.5, 0, 0, 0.5, 1, 1]\n",
    "    df = create_random_dataframe_with_params(n_rows = 100000, n_cols = 8, params = params, seed = 42)\n",
    "    \n",
    "\n",
    "    train, temp = train_test_split(df, test_size=0.4, random_state=42)\n",
    "    test, valid = train_test_split(temp, test_size=0.5, random_state=42)\n",
    "\n",
    "    train = train[['target', \"col_1\", \"col_2\", \"col_3\", \"col_6\", \"col_7\", \"col_8\"]]\n",
    "    test = test[['target', \"col_1\", \"col_2\", \"col_3\", \"col_6\", \"col_7\", \"col_8\"]]\n",
    "    valid = valid[['target', \"col_1\", \"col_2\", \"col_3\", \"col_6\", \"col_7\", \"col_8\"]]\n",
    "    inference_train = train[[\"col_1\", \"col_2\", \"col_3\", \"col_6\", \"col_7\", \"col_8\"]]\n",
    "\n",
    "    train_path = os.path.join(settings[\"preprocessing_output_train\"], \"train.csv\")\n",
    "    train.to_csv(train_path, index=False, float_format='%.5f')\n",
    "\n",
    "    test_path = os.path.join(settings[\"preprocessing_output_test\"], \"test.csv\")\n",
    "    test.to_csv(test_path, index=False, float_format='%.5f')\n",
    "\n",
    "    valid_path = os.path.join(settings[\"preprocessing_output_valid\"], \"valid.csv\")\n",
    "    valid.to_csv(valid_path, index=False, float_format='%.5f')\n",
    "\n",
    "    inference_train_path = os.path.join(settings[\"preprocessing_output_inference_train\"], \"inference_train.csv\")\n",
    "    inference_train.to_csv(inference_train_path, index=False, float_format='%.5f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c4d6553-a047-4e01-8444-781739786e62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to only available Python version: py3\n"
     ]
    }
   ],
   "source": [
    "sklearn_processor = SKLearnProcessor(\n",
    "    framework_version=\"0.23-1\",\n",
    "    instance_type='ml.t3.medium',\n",
    "    instance_count=1,\n",
    "    base_job_name=settings['preprocessing_job_name'],\n",
    "    sagemaker_session=pipeline_session,\n",
    "    role=role,\n",
    "    env=settings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf8825d4-a4ce-479c-88d2-580066ef2db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sagemaker/workflow/pipeline_context.py:332: UserWarning: Running within a PipelineSession, there will be No Wait, No Logs, and No Job being started.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_s3_path = os.path.join(\"s3://\",settings['bucket_name'],settings['project_path_s3'],'data','train')\n",
    "test_s3_path = os.path.join(\"s3://\",settings['bucket_name'],settings['project_path_s3'],'data','test')\n",
    "valid_s3_path = os.path.join(\"s3://\",settings['bucket_name'],settings['project_path_s3'],'data','valid')\n",
    "inference_train_s3_path = os.path.join(\"s3://\",settings['bucket_name'],settings['project_path_s3'],'data','inference_train')\n",
    "\n",
    "processor_args = sklearn_processor.run(\n",
    "    inputs=[],\n",
    "    outputs=[\n",
    "        ProcessingOutput(\n",
    "            output_name=\"train\",\n",
    "            source=settings[\"preprocessing_output_train\"],\n",
    "            destination=train_s3_path),\n",
    "        ProcessingOutput(\n",
    "            output_name=\"test\",\n",
    "            source=settings[\"preprocessing_output_test\"],\n",
    "            destination=test_s3_path),\n",
    "        ProcessingOutput(\n",
    "            output_name=\"valid\",\n",
    "            source=settings[\"preprocessing_output_valid\"],\n",
    "            destination=valid_s3_path),\n",
    "        ProcessingOutput(\n",
    "            output_name=\"inference_train\",\n",
    "            source=settings[\"preprocessing_output_inference_train\"],\n",
    "            destination=inference_train_s3_path)        \n",
    "\n",
    "    ],\n",
    "    code=\"scripts/processing.py\",\n",
    ") \n",
    "\n",
    "step_process = ProcessingStep(\n",
    "    name=settings[\"preprocessing_step_name\"],\n",
    "    step_args=processor_args\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b5fdc19-2a5c-4252-a9e2-ff931aac3207",
   "metadata": {},
   "outputs": [],
   "source": [
    "environment = {\n",
    "    'mlflow_arn': settings['mlflow_arn'],\n",
    "    'mlflow_experiment_name': settings['mlflow_experiment_name'],\n",
    "    'mlflow_final_model_name': 'final-model2',\n",
    "    'mlflow_model_name': settings['mlflow_model_name']\n",
    "}\n",
    "\n",
    "sklearn = SKLearn(\n",
    "    entry_point='train.py', # The file with the training code\n",
    "    source_dir='scripts', # The folder with the training code\n",
    "    framework_version='1.2-1', # Version of SKLearn which will be used\n",
    "    instance_type='ml.m5.large', # Instance type that wil be used\n",
    "    role=role, # Role that will be used during execution\n",
    "    sagemaker_session=pipeline_session, \n",
    "    base_job_name=settings['training_job_name'], # Name of the training job. Timestamp will be added as suffix\n",
    "    environment = environment\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "819e22f7-f540-456f-beee-246fa3bd5b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_args = sklearn.fit({\"train\": step_process.properties.ProcessingOutputConfig.Outputs['train'].S3Output.S3Uri})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b2e1648-8685-4667-9914-b3f2718789c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "step_train = TrainingStep(\n",
    "    name=settings[\"training_step_name\"],\n",
    "    step_args = train_args\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8eb6f65-1557-42d7-8fc8-211746950220",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(settings['mlflow_arn'])\n",
    "mlflow.set_experiment(settings['mlflow_experiment_name'])\n",
    "client = MlflowClient()\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ce3b4d9-bf03-4900-9124-0e51f0b4f9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "registered_model = client.get_registered_model(name=settings['mlflow_model_name'])\n",
    "run_id = registered_model.latest_versions[0].run_id\n",
    "source_path = registered_model.latest_versions[0].source\n",
    "model_path = os.path.join(source_path, 'model.tar.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b02de8d-9479-4290-a153-3bbcf75c1472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the SKLearnModel\n",
    "sklearn_model = SKLearnModel(\n",
    "    model_data=model_path,\n",
    "    entry_point='inference.py', # The file with the training code\n",
    "    source_dir=\"scripts\", # The folder with the training code\n",
    "    role=role,\n",
    "    framework_version='1.2-1',  # Replace with the appropriate sklearn version\n",
    "    sagemaker_session=pipeline_session\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "11fbe9b4-c799-4ae6-b147-5bbd019a3778",
   "metadata": {},
   "outputs": [],
   "source": [
    "step_create_model = ModelStep(\n",
    "   name=settings[\"modelcreate_step_name\"],\n",
    "   step_args=sklearn_model.create(instance_type=\"ml.m5.large\"),\n",
    "    depends_on=[step_train]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "70af832a-60b1-4681-8261-a86e1da75c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_output_path = os.path.join(\"s3://\",settings['bucket_name'],settings['project_path_s3'],'output','inference_train')\n",
    "\n",
    "transformer = Transformer(\n",
    "    model_name=step_create_model.properties.ModelName,\n",
    "    instance_type=\"ml.m5.large\",\n",
    "    instance_count=1,\n",
    "    output_path=transformer_output_path,\n",
    "    accept=\"text/csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b8a963a4-8585-4a0e-91da-1648dab54d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "step_transform = TransformStep(\n",
    "    name=settings[\"transformer_step_name\"],\n",
    "    transformer=transformer,\n",
    "    inputs=TransformInput(\n",
    "        data=step_process.properties.ProcessingOutputConfig.Outputs['inference_train'].S3Output.S3Uri,\n",
    "        content_type='text/csv', # It is neccessary because csv is not default format\n",
    "        split_type='Line' # Each line equals one observation)\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9aab9e12-dd93-477f-8856-10497a208653",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_name = f\"01-churn-deploy-model\"\n",
    "pipeline = Pipeline(\n",
    "    name=pipeline_name,\n",
    "    steps=[step_process, step_train, step_create_model, step_transform],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d48f7f59-4a06-41d8-b9a6-074f16e8ec96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'TrainingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ModelName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'TransformJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'TrainingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ModelName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'TransformJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'PipelineArn': 'arn:aws:sagemaker:eu-west-1:211125740051:pipeline/01-churn-deploy-model',\n",
       " 'ResponseMetadata': {'RequestId': 'd935880a-4400-46db-8c82-9a8d8e28d22a',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'd935880a-4400-46db-8c82-9a8d8e28d22a',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '89',\n",
       "   'date': 'Mon, 15 Jul 2024 12:24:43 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.upsert(role_arn=role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "abe111fc-2f8c-47d8-9d81-5d4ebad2fbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "execution = pipeline.start()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
